{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d7e48d6",
   "metadata": {},
   "source": [
    "<h1>scikit-learn</h1>\n",
    "- 프레임워크, API제공"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e04f8a",
   "metadata": {},
   "source": [
    "<h3>3.1 분류 (Classification)</h3>\n",
    "- 지도학습(Aupervised learning) 방법 중 하나\n",
    "\n",
    "<h5>** 지도학습</h5>\n",
    "\n",
    "- 다양한 피처와 분류 결정값인 레이블(Lable) 데이터로 모델을 한습한 후, 별도의 테스트 데이터 세트에서 미지의 레이블을 예측<br>\n",
    "\n",
    "- 먕확한 정답이 주어진 데이터 先학습， 後 미지의 정답 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ba7769",
   "metadata": {},
   "source": [
    "<h5>사이킷런 모듈</h5>\n",
    "\n",
    "(1) sklearn.datasets\n",
    "- 사이킷런 자체 제공 데이터 세트 생성 모듈\n",
    "\n",
    "(2) sklearn.tree\n",
    "- 트리기반 ML 알고리즘\n",
    "\n",
    "(3) sklearn.model_selection\n",
    "- 학습 데이터, 검증 데이터 통칭\n",
    "- 하이퍼 파라미터를 통해 머신러닝 알고리즘의 성능 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f69cef40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris target값: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "iris target명: ['setosa' 'versicolor' 'virginica']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 붓꽃 데이터 세트 로딩\n",
    "iris = load_iris()\n",
    "\n",
    "# iris_data : 붓꽃 데이터 세트에서 feature만으로 된 데이터를 numpy로 가지고 있음\n",
    "iris_data = iris.data\n",
    "\n",
    "# iris_label : 붓꽃 데이터 세트에서 label(결정 값) 데이터를 numpy로 가지고 있음\n",
    "iris_label = iris.target\n",
    "print('iris target값:', iris_label)\n",
    "print('iris target명:', iris.target_names)\n",
    "\n",
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "iris_df['label'] = iris_label\n",
    "iris_df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b66e383",
   "metadata": {},
   "source": [
    "<h5>▲ Result </h5>\n",
    "\n",
    "(1) feature\n",
    "- sepal length\n",
    "- sepal width\n",
    "- petal length\n",
    "- petal width\n",
    "\n",
    "(2) label\n",
    "- 0 : Setosa 품종\n",
    "- 1 : versicolor 품종\n",
    "- 2 : verginica 품종"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aef85df",
   "metadata": {},
   "source": [
    "<h4>학습용 데이터 및 테스트용 데이터 분리</h4>\n",
    "\n",
    "- 학습 데이터로 학습된 모델의 성능 평가를 위해 테스트 데이터 세트 필요\n",
    "- train_test_split()\n",
    "\n",
    "(1) train_test_split()\n",
    "- 학습 데이터와 테스트 데이터를 test_size 파라미터 입력값의 비율로 분할\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74926a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris target값: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "iris target명: ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 붓꽃 데이터 세트 로딩\n",
    "iris = load_iris()\n",
    "\n",
    "# iris_data : 붓꽃 데이터 세트에서 feature만으로 된 데이터를 numpy로 가지고 있음\n",
    "iris_data = iris.data\n",
    "\n",
    "# iris_label : 붓꽃 데이터 세트에서 label(결정 값) 데이터를 numpy로 가지고 있음\n",
    "iris_label = iris.target\n",
    "print('iris target값:', iris_label)\n",
    "print('iris target명:', iris.target_names)\n",
    "\n",
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "iris_df['label'] = iris_label\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris_data, iris_label, test_size = 0.2, random_state=11)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00b489d",
   "metadata": {},
   "source": [
    "feature\n",
    "- iris_data\n",
    "\n",
    "lable\n",
    "- iris_lable\n",
    "\n",
    "test data set 비율\n",
    "- test_size = 0.2\n",
    "\n",
    "난수 발생 값 (호출 마다 같은 학습/테스트 용 데이터 세트 생성을 위한)<br>\n",
    "- random_state\n",
    "\n",
    "** train_test_split() 호출 시 무작위로 데이터를 분리하므로 random_state() 지정 필요<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4adabdd",
   "metadata": {},
   "source": [
    "** DecisionTreeClassifier()\n",
    "- 의사결정 트리 클래스\n",
    "- random_state= 지정 \n",
    "- 학습/예측 결과 출력\n",
    "- fit() : 학습용 피처 데이터 속성과 결정 값 데이터 세트 입력 \n",
    "\n",
    "\n",
    "** fit()\n",
    "- 모델을 학습하는 단계 (피처와 레이블로)\n",
    "\n",
    "** predict()\n",
    "- 학습이 끝난 모델이 답을 내는 단계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e499d7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris target값: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "iris target명: ['setosa' 'versicolor' 'virginica']\n",
      "예측 정확도:  0.933333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 붓꽃 데이터 세트 로딩\n",
    "iris = load_iris()\n",
    "\n",
    "# iris_data : 붓꽃 데이터 세트에서 feature만으로 된 데이터를 numpy로 가지고 있음\n",
    "iris_data = iris.data\n",
    "\n",
    "# iris_label : 붓꽃 데이터 세트에서 label(결정 값) 데이터를 numpy로 가지고 있음\n",
    "iris_label = iris.target\n",
    "print('iris target값:', iris_label)\n",
    "print('iris target명:', iris.target_names)\n",
    "\n",
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "iris_df['label'] = iris_label\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris_data, iris_label, test_size = 0.2, random_state=11)\n",
    "\n",
    "# DecisionTreeClassifier 객체 생성\n",
    "dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "\n",
    "# 학습 수행\n",
    "dt_clf.fit(x_train, y_train)\n",
    "\n",
    "# 학습 완료된 DecisionTreeClassifier 객체에서 테스트 데이터 세트로 예측 수행\n",
    "pred = dt_clf.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('예측 정확도: {0: 4F}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3983ffa3",
   "metadata": {},
   "source": [
    "** 정확도 측정\n",
    "\n",
    "- accuracy_acore()\n",
    "- 실제 데이터 세트, 예측 레이블 데이터 세트 순으로 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67a5bf9",
   "metadata": {},
   "source": [
    "** 분류 예측 프로세스\n",
    "\n",
    "(1) 데이터 세트 분리 : 학습/테스트 데이터 분리<br>\n",
    "(2) 모델 학습 : 학습 데이터 기반으로 모델 학습<br>\n",
    "(3) 예측 수행 : 학습된 ML 모델로 테스트 데이터의 분류 예측<br>\n",
    "(4) 평가 : 예측된 결과값, 테스트 데이터의 실제 결과값 비교 후 모델 성능 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f4adbf",
   "metadata": {},
   "source": [
    "<h3>3.2 사이킷런 기반 프레임워크</h3>\n",
    "\n",
    "<h4>3.2.1 Estimator 이해 및 fit(), predict()</h4>\n",
    "\n",
    "- fit() : ML 모델 학습\n",
    "- predict() : 학습된 모델의 예측\n",
    "- 지도학습 : 분류(Classifier) / 회귀(Regressor) 클래스에서 fit(), predict()으로 간단하게 학습 및 예측 결과 반환 가능\n",
    "- Estimator 클래스 = 분류(Classifier) + 회귀(Regressor)\n",
    "\n",
    "\n",
    "- cross_val_score() : evaluation 함수\n",
    "- GridSearchCV : 파라미터 튜닝\n",
    "- cross_val_score(), GridSearchCV.fit() : Estimator의 fit(), predict()를 호출해 평가 및 파라미터 튜닝 수행\n",
    "\n",
    "\n",
    "<h5>** 비지도 학습에서의 fit(), transform() 사용법</h5>\n",
    "\n",
    "- 비지도학습 : 차원 축소 / 클러스터링 / 피처 추출(Feature Extraction) \n",
    "- fit() : 비지도 학습 및 피처 추출에서 fit() 사용시 압력데이터의 형태에 맞춰 데이터를 변환해주기 위해 사전 구조를 맞추는 작업 진행\n",
    "- transform() : 차원 변환, 클러스터링, 피처 추출 등 실제 작업 진행\n",
    "\n",
    "- fit_transform() : fit()과 transform()의 결합물<br>\n",
    "    => fit()과 transform()을 별도로 호출하지 않아도 됨\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b32794b",
   "metadata": {},
   "source": [
    "<h4>3.2.2 사이킷런의 주요 모듈</h4>\n",
    "\n",
    "\n",
    "<h5>(1) 예제 데이터</h5>\n",
    "\n",
    "- sklearn.datasets : 내장돤 예제 제공  데이터 세트\n",
    "\n",
    "<h5>(2) 피처 처리</h5>\n",
    "\n",
    "- sklearn.preprocessing<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 데이터 전처리에 필요한 가공 기능 (문자열을 숫자형 코드값으로 인코딩, 정규화, 스케일링 등)\n",
    "\n",
    "- sklearn.feature_selection<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 일고리즘에 큰 영향을 미치는 피처를 우선순위대로 셀렉션 작업을 수행 기능 제공\n",
    "\n",
    "- sklearn.feature_extraction<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 텍스트, 이미지 데이터의 벡터화된 피처를 추출시 사용<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 텍스트 데이터 내 Count Vectorizer, TF-IDF Vectorizer 생산 기능 제공<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 텍스트 데이터 피처 추출 : sklearn.feature_extraction.text<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 이미지 데이터 피처 추출 : sklearn.feature_extraction.image<br>\n",
    "\n",
    "<h5>(3) 피처 처리 & 차원 축소</h5>\n",
    "\n",
    "- sklearn.decomposition<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 차원 축소 관련 알고리즘 지원 모듈 <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> PCA, NMF, Truncated SVD 등을 이용해 차원 축소<br>\n",
    "\n",
    "<h5>(4) 데이터 분리, 검증 & 파라미터 튜닝</h5>\n",
    "\n",
    "- sklearn.model_selection<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 교차 검증을 위한 학습/테스트 용 분리, 그리드 서치로 최적의 파라미터 추출 등 API 제공<br>\n",
    "\n",
    "<h5>(5) 평가</h5>\n",
    "\n",
    "- sklearn.metric<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 분류, 회귀, 클러스터링, 페어와이즈(Pairwise)에 대한 다양한 성능 측정 방법<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> Accuracy, Precsion, Recal, ROC-AUC, RMSE 제공<br>\n",
    "\n",
    "<h5>(6) ML 알고리즘</h5>\n",
    "\n",
    "- sklearn.ensemble<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 앙상블 알고리즘 제공<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 랜덤 포레스트, 에이다 부스트, 그래디언트 부스팅 제공<br>\n",
    "\n",
    "- sklearn.linear_model<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 선형회귀, 릿지(Ridge), 라쏘(Lasso), 로지스틱 회귀 등 회귀 관련 알고리즘 지원<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> SGD(Stochastic Gradient Descent) 알고리즘 제공<br>\n",
    "\n",
    "- sklearn.naive_bayes<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 나이브 베이즈 알고리즘 제공<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 기우시안 NB, 다항분포 NB 제공<br>\n",
    "\n",
    "- sklearn.neighbors<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 최근접 이웃 알고리즘, K-NN<br>\n",
    "\n",
    "- sklearn.svm<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 서포트 벡터 머신 제공<br>\n",
    "\n",
    "- sklearn.tree<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 의사결정 트리 제공<br>\n",
    "\n",
    "- sklearn.cluster<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 비지도 클러스터링 제공<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> K-평균, 계층형, DBSCAN<br>\n",
    "\n",
    "<h5>(7) 유틸리티</h5>\n",
    "\n",
    "- sklearn.pipeline<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 피처 처리 등 변환, ML 알고리즘 학습, 예측 등을 함께 묶어 실행 가능한 유틸리티 제공<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3070489d",
   "metadata": {},
   "source": [
    "<h4>3.2.3 내장돤 예제 데이터 세트</h4>\n",
    "- fetch : 데이터 크기가 커 인터넷에서 다운 받아 사용\n",
    "\n",
    "<h5>** 표본 데이터 생성기</h5>\n",
    "\n",
    "(1) 분류<br>\n",
    "- datasets.make_classifications()<br>\n",
    "    => 분류를 위한 데이터 세트 생성<br>\n",
    "    => 높은 상관도, 불필요한 속성 등 노이즈 효과를 위한 데이터 무작위로 생성<br>\n",
    "\n",
    "(2) 클러스터링<br>\n",
    "- datasets.make_classifications()<br>\n",
    "    => 클러스터링를 위한 데이터 세트 무작위 생성<br>\n",
    "    => 군집 지정 개수에 따라 여러 가지 클러스터링을 위한 데이터 무작위로 생성<br>\n",
    "\n",
    "<h5>** 내장 데이터 구성</h5>\n",
    "- 딕셔너리 형태<br>\n",
    "- 키 : data, target, target_name, feature_names, DESCR로 구성<br>\n",
    "\n",
    "(1) 넘파이 배열(ndarray)<br>\n",
    "&nbsp;&nbsp;&nbsp;=> data : 피처의 데이터 세트 <br>\n",
    "&nbsp;&nbsp;&nbsp;=> target : 분류 시 레이블 값 / 회귀 시 숫자 결과값 데이터 세트<br>\n",
    "\n",
    "(2) 넘파이 배열(ndarray) & 파이썬 list<br>\n",
    "&nbsp;&nbsp;&nbsp;=> target_name : 개별 레이블 이름<br>\n",
    "&nbsp;&nbsp;&nbsp;=> feature_names : 피처 명<br>\n",
    "\n",
    "(3) String 타입<br>\n",
    "&nbsp;&nbsp;&nbsp;=> DESCR : 데이터 세트 설명 및 각 피처의 설명<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa19da72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils._bunch.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "print(type(iris_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a912c67f",
   "metadata": {},
   "source": [
    "** bunch\n",
    "- 파이썬 딕셔너리 형태와 유사 / 딕셔너리 형태의 값 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef0af454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트의 키들: dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "keys = iris_data.keys()\n",
    "\n",
    "print('붓꽃 데이터 세트의 키들:', keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f4d2056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " feature_names의 type: <class 'list'>\n",
      "\n",
      " feature_names의 shape: 4\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "\n",
      " target_names의 type: <class 'numpy.ndarray'>\n",
      "\n",
      " target_names의 shape: 3\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "\n",
      " data의 type: <class 'numpy.ndarray'>\n",
      "data 의 shape: (150, 4)\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "\n",
      " data의 type: <class 'numpy.ndarray'>\n",
      "data 의 shape: (150,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "keys = iris_data.keys()\n",
    "\n",
    "print('\\n feature_names의 type:', type(iris_data.feature_names))\n",
    "print('\\n feature_names의 shape:', len(iris_data.feature_names))\n",
    "print(iris_data.feature_names)\n",
    "\n",
    "print('\\n target_names의 type:', type(iris_data.target_names))\n",
    "print('\\n target_names의 shape:', len(iris_data.target_names))\n",
    "print(iris_data.target_names)\n",
    "\n",
    "print('\\n data의 type:', type(iris_data.data))\n",
    "print('data 의 shape:', iris_data.data.shape)\n",
    "print(iris_data['data'])\n",
    "\n",
    "print('\\n data의 type:', type(iris_data.target))\n",
    "print('data 의 shape:', iris_data.target.shape)\n",
    "print(iris_data.target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6deccc84",
   "metadata": {},
   "source": [
    "<h3>3.3 Model Selection 모듈 소개</h3>\n",
    "\n",
    "- 학습 / 테스트 데이터 분리\n",
    "- 교차 검증 분할 및 평가\n",
    "- Estimator의 하이퍼 파라미터 튜닝\n",
    "\n",
    "<h4>3.3.1 학습/테스트 데이터 분리 - train_test_split()</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b30a44cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 학습과 예측을 동일 데이터 세트로 진행 예제\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "df_clf = DecisionTreeClassifier()\n",
    "train_data = iris.data\n",
    "train_label = iris.target\n",
    "df_clf.fit(train_data, train_label)\n",
    "\n",
    "# 학습 데이터 세트로 예측 수행\n",
    "pred = df_clf.predict(train_data)\n",
    "print('예측 정확도:', accuracy_score(train_label, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc06c5c",
   "metadata": {},
   "source": [
    "** 학습과 예측을 동일 데이터 세트로 진행 예제 <br>\n",
    "결과 : 정확도 = 100%<br>\n",
    "    => 이미 학습한 데이터 세트를 기반으로 예측 진행<br>\n",
    "    => 오류 발생<br>\n",
    "\n",
    "해결법 :<br>\n",
    "    => 예측 수행 데이터 세트 = 예측 전용 데이터 세트여야 함<br>\n",
    "    => train_test_split() 사용해 학습/테스트 데이터 분리\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95581169",
   "metadata": {},
   "source": [
    "train_test_split() 파라미터 입력\n",
    "\n",
    "- test_size<br>\n",
    "    => 전체 데이터에서 테스트 데이터 세트 크기 얼마로 샘플링 할 것인지 결정<br>\n",
    "    => 디폴 값 : 0.25 == 25%<br>\n",
    "\n",
    "- train_size<br>\n",
    "    => 전체 데이터에서 학습 데이터 세트 크기를 얼마로 샘플링할 것인지 결정<br>\n",
    "    => 자주 사용 x<br>\n",
    "    => test_size_parameter를 주로 사용<br>\n",
    "\n",
    "- shuffle<br>\n",
    "    => 데이터를 분리하기 전 데이터를 미리 섞을지 결정 <br>\n",
    "    => 데이터를 분산시켜 좀 더 효율적인 학습 및 테스트 데이터 세트를 만드는데 사용\n",
    "    => 디폴트 값 : True<br>\n",
    "\n",
    "- random_state<br>\n",
    "    => 호출할 때 마다 동일한 학습/테스트 데이터 세트 생성을 위해 주어지는 난수 값<br>\n",
    "    => train_test_split() 사용 시 무작위로 데이터 생성 됨 따라서 동일한 학습/테스트 데이터 세트 생성을 위해 random_state 지정 필요<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26148ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 0.9556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_clf = DecisionTreeClassifier()\n",
    "iris_data = load_iris()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, \n",
    "                                                    test_size=0.3, random_state=121)\n",
    "\n",
    "df_clf.fit(x_train, y_train)\n",
    "pred = df_clf.predict(x_test)\n",
    "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31fdb49",
   "metadata": {},
   "source": [
    "<h3>3.4 교차 검증</h3>\n",
    "\n",
    "** 교차 검증이 필요한 이유<br>\n",
    "- 과적합(Overfitting) : 학습 데이터에만 과도하게 최적화되어 다른 데이터로 실제 예측을 진행 할 때 예측 성능이 과도하게 떨어짐 <br>\n",
    "\n",
    "** 교차 검증\n",
    "- 데이터 편증 : ML 알고리즘에서 최적의 동작을 위해 데이터를 선별해 학습할 셩우 실제 데이터 양식과 큰 차이가 발생하며 성능저하로 이어지게 됨 <br>\n",
    "- 데이터 편증을 막기 위해 수 많은 학습과 검증 세트에서 알고리즘 학습과 평가를 수행<br>\n",
    "- 평가 결과에 따라 하이퍼 파라미터 튜닝 등의 모델 최적화를 쉽게 진행 할 수 있게 됨<br>\n",
    "\n",
    "** ML 모델의 성능 평가<br>\n",
    "- 교차검증을 기반으로 1차 평가 진행<br>\n",
    "- 최종적으로 테스트 데이터 세트에 적용해 평가 진행<br>\n",
    "- ML에 사용되는 테스트 데이터를 세분화해 학습/검증/테스트 데이터 세트로 나눌 수 있음<br>\n",
    "- 테스트 데이터 세트 외 별도의 검증 데이터 세트를 사용해 최종 평가 이전에 학습된 모델을 다양하게 평가하는데 사용<br>\n",
    "\n",
    "<h4>3.4.1 K 폴드 교차검증</h4>\n",
    "\n",
    "- KFold 모델<br>\n",
    "- StratifieldKFold 모델<br>\n",
    "- 가장 보편적으로 사용되는 교차 검증<br>\n",
    "- K개의 데이터 폴드 세트를 생성 후 K번 만큼 각 폴드 세트에 학습/검증 평가를 반복적으로 수행<br>\n",
    "\n",
    "\n",
    "** K 폴드 교차 검증 예시(5폴드 교차 검증)<br>\n",
    "- 5개의 폴드된 학습/검증 데이터 세트를 변경하며 생성 -> 5번 평가 수행<br>\n",
    "- 예측성능 평가<br>\n",
    "- 데이터 세트를 K등분(5등분)하여 아래의 과정 진행<br>\n",
    "    ✦ 1번째 ==> 1~4: 학습 / 5:검증<br>\n",
    "    ✦ 2번째 ==> 1~3: 학습 / 4: 검증 / 5: 학습<br>\n",
    "    ✦ 3번째 ==> 1~2: 학습 / 3: 검증 / 4~5: 학습<br>\n",
    "    ✦ 4번째 ==> 1: 학습 / 2: 검증 / 3~5: 학습<br>\n",
    "    ✦ 5번째 ==> 1: 검증 / 2~5: 학습<br>\n",
    "- K폴드 평과 결과 : 5개의 예측평가 진행 후 평균값을 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2a0c183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트 크기: 150\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "df_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "#  5개의 폴드 세트로 분리하는 KFold 객체 & 폴드 세트별 정확도를 담을 리스트 객체 생성\n",
    "kfold = KFold(n_splits=5)\n",
    "cv_accuracy = []\n",
    "print('붓꽃 데이터 세트 크기:', features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbd66930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차 검증 정확도 :1.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#1 검증 세트 인덱스:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "#2 교차 검증 정확도 :0.9667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#2 검증 세트 인덱스:[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "\n",
      "#3 교차 검증 정확도 :0.8667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#3 검증 세트 인덱스:[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "\n",
      "#4 교차 검증 정확도 :0.9333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#4 검증 세트 인덱스:[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "\n",
      "#5 교차 검증 정확도 :0.7333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#5 검증 세트 인덱스:[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "## 평균 검증 정확도: 0.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.datasets import load_iris  # 추가\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()  # iris 데이터셋 로드\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "df_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "cv_accuracy = []\n",
    "\n",
    "n_iter = 0\n",
    "\n",
    "# KFold 개ㄱ체의 split()를 호출하면 폴드별 학습/검증용 테스트의 로우 인덱스를 array로 반환\n",
    "for train_index, test_index in kfold.split(features):\n",
    "    # kfold.split()로 반환된 인덱스를 이용해 학습/검증용 테스트 데이터 추출\n",
    "    x_train, x_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    \n",
    "    # 학습 및 예측\n",
    "    df_clf.fit(x_train, y_train)\n",
    "    pred = df_clf.predict(x_test)\n",
    "    n_iter += 1\n",
    "    \n",
    "    # 반복시 마다 정확도 측정\n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "    train_size = x_train.shape[0]\n",
    "    test_size = x_test.shape[0]\n",
    "    print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'.format(n_iter, accuracy, train_size, test_size))\n",
    "    print('#{0} 검증 세트 인덱스:{1}'.format(n_iter, test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "\n",
    "# 개별 iteration별 정확도를 합하여 평균 정확도 계산\n",
    "print('\\n## 평균 검증 정확도:', np.mean(cv_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f557bd49",
   "metadata": {},
   "source": [
    "<h4>3.4.2 Stratified K폴드</h4>\n",
    "\n",
    "** 불균형한 분포도를 가진 레이블 데이터 집합<br>\n",
    "- 특정 레이블 값이 특이하게 많거나 매우 적어서 값의 분포가 한쪽으로 치우쳐지는 것<br>\n",
    "\n",
    "- 불균형한(imbalanced)분포도를 가진 레이블(결정 클래스) 데이터 집합을 위한 K폴드 방식<br>\n",
    "- K폴드가 레이블 데이터 집합이 원본 데이터 집합의 레이블 분포를 학습 및 테스트 세트에 제대로 분배하지 못하는 경우의 문제를 해결<br>\n",
    " => 원본 데이터의 레이블 분포를 우선 고려 후 이 분포와 동일하게 학습과 검증 데이터 세트를 분배"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99c51f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    50\n",
       "1    50\n",
       "2    50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['label']=iris.target\n",
    "iris_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "443e4bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차검증: 1\n",
      "학습 레이블 데이터 분포:\n",
      " label\n",
      "1    50\n",
      "2    50\n",
      "Name: count, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " label\n",
      "0    50\n",
      "Name: count, dtype: int64\n",
      "## 교차검증: 2\n",
      "학습 레이블 데이터 분포:\n",
      " label\n",
      "0    50\n",
      "2    50\n",
      "Name: count, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " label\n",
      "1    50\n",
      "Name: count, dtype: int64\n",
      "## 교차검증: 3\n",
      "학습 레이블 데이터 분포:\n",
      " label\n",
      "0    50\n",
      "1    50\n",
      "Name: count, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " label\n",
      "2    50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['label']=iris.target\n",
    "iris_df['label'].value_counts()\n",
    "\n",
    "kfold = KFold(n_splits=3)\n",
    "n_iter = 0\n",
    "for train_index, test_index in kfold.split(iris_df):\n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print('## 교차검증: {0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826b836e",
   "metadata": {},
   "source": [
    "KFold(n_splits=3)<br>\n",
    "학습/검증 레이블이 교차 검증시 3개의 폴드 세트로 만들어짐<br>\n",
    "\n",
    "**결과\n",
    "\n",
    "학습레이블에서 1과 2의 값이 각각 50개 추출<br>\n",
    "검증데이터에서 0값이 50개 추출<br>\n",
    "\n",
    "=> 학습 모델은 절대 0을 예측 할 수 없음<br>\n",
    "=> 교차 검증 데이터 세트 분할 시 검증 에측 정화도 = 0임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "323565d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차 검증1\n",
      "학습 레이블 데이터 분포:\n",
      " label\n",
      "2    34\n",
      "0    33\n",
      "1    33\n",
      "Name: count, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " label\n",
      "0    17\n",
      "1    17\n",
      "2    16\n",
      "Name: count, dtype: int64\n",
      "## 교차 검증1\n",
      "학습 레이블 데이터 분포:\n",
      " label\n",
      "1    34\n",
      "0    33\n",
      "2    33\n",
      "Name: count, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " label\n",
      "0    17\n",
      "2    17\n",
      "1    16\n",
      "Name: count, dtype: int64\n",
      "## 교차 검증1\n",
      "학습 레이블 데이터 분포:\n",
      " label\n",
      "0    34\n",
      "1    33\n",
      "2    33\n",
      "Name: count, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " label\n",
      "1    17\n",
      "2    17\n",
      "0    16\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "iris_df['label'].value_counts()\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
    "    n_iter = 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    \n",
    "    print('## 교차 검증{0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec5d807",
   "metadata": {},
   "source": [
    "StratifiedKFold는 레이블 데이터 분포도에 따라 학습/검증 데이터를 나누기 때문에 split() 메서드에 인자로 피처 데이터 세트뿐만 아니라 레이블 데이터 세트도 필요\n",
    "\n",
    "ex) for train_index, test_index in skf.split(iris_df, iris_df['label']):<br>\n",
    "<br>\n",
    "<br>\n",
    "** 결과\n",
    "\n",
    "- 학습 레이블과 검증 레이블 데이터 값의 분포도가 거의 동일하게 할당됨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb5d85ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차 검증 정확도 :0.98, 학습 데이터 크기 :100, 검증 데이터 크기 :50\n",
      "#1 검증 세트 인덱스:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n",
      "\n",
      "## 교차 검증별 정확도: [0.98]\n",
      "\n",
      "## 평균 검증 정확도: 0.98\n",
      "\n",
      "#2 교차 검증 정확도 :0.94, 학습 데이터 크기 :100, 검증 데이터 크기 :50\n",
      "#2 검증 세트 인덱스:[ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
      "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
      "\n",
      "## 교차 검증별 정확도: [0.98 0.94]\n",
      "\n",
      "## 평균 검증 정확도: 0.96\n",
      "\n",
      "#3 교차 검증 정확도 :0.98, 학습 데이터 크기 :100, 검증 데이터 크기 :50\n",
      "#3 검증 세트 인덱스:[ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
      "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "## 교차 검증별 정확도: [0.98 0.94 0.98]\n",
      "\n",
      "## 평균 검증 정확도: 0.9667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "# iris_df['label'] = iris.target\n",
    "# iris_df['label'].value_counts()\n",
    "\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "\n",
    "df_clf =DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "skfold = StratifiedKFold(n_splits=3)\n",
    "n_iter = 0\n",
    "cv_accuracy=[]\n",
    "\n",
    "# StratifiedKFold의 split() 호출 시 반드시 레이블 데이터 세트도 추가 입력\n",
    "for train_index, test_index in skfold.split(features, label):\n",
    "    #split()으로 반환된 인덱스를 이용해 학습/검증용 테스트 데이터 추출 가능\n",
    "    x_train, x_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    \n",
    "    # 학습 / 예측\n",
    "    df_clf.fit(x_train, y_train)\n",
    "    pred = df_clf.predict(x_test)\n",
    "    \n",
    "    # 반복 시 마다 정확도 측정\n",
    "    n_iter += 1\n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "    train_size = x_train.shape[0]\n",
    "    test_size = x_test.shape[0]\n",
    "    \n",
    "    print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기 :{2}, 검증 데이터 크기 :{3}'.format(n_iter, accuracy, train_size, test_size))\n",
    "    print('#{0} 검증 세트 인덱스:{1}'.format(n_iter, test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "    # 교차 검증별 정확도 및 평균 정확도 계산\n",
    "    print('\\n## 교차 검증별 정확도:', np.round(cv_accuracy, 4))\n",
    "    print('\\n## 평균 검증 정확도:', np.round(np.mean(cv_accuracy), 4))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e37b8e",
   "metadata": {},
   "source": [
    "Stratified KFold의 경우 원본 데이터의 레이블 분포도 특성을 반영한 학습 및 검증 데이터 세트를 만들 수 있음<br>\n",
    "=> 왜곡된 레이블 데이터 세트에서 Stratified KFold 교차 검증 필요\n",
    "\n",
    "- 분류(Classfication) : Stratified KFold 교차 검증<br>\n",
    "- 회귀(Regression) : Stratified KFold 지원 x<br>\n",
    "    => 회귀 결정값 = 연속된 숫자값이므로 결정값 분포를 정하는 의미가 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2b56ec",
   "metadata": {},
   "source": [
    "<h4>3.4.3 교차 검증을 편하게 - cross_val_score()</h4>\n",
    "\n",
    "- KFold로 데이터를 학습하고 예측할 때<br>\n",
    "(1) 폴드 세트 설정<br>\n",
    "(2) for 루프에서 반복으로 학습 및 테스트 데이터의 인덱스를 추출 후 <br>\n",
    "(3) 반복적으로 학습과 예측을 수행하고 예측 성능을 반환<br>\n",
    "\n",
    "<h5>cross_val_score()란?</h5>\n",
    "- 위의 모든 과정을 한꺼번에 수행하는 API<br>\n",
    "- 단 하나의 평가 지표만 가능<br>\n",
    "\n",
    "** 사용방법\n",
    "- cross_val_score() 수행 후 반환 값은 scoring 파라미터로 지정된 성능 지표 측정값을 배열 형태로 반환<br>\n",
    "        => ❖ 이를 평균해 평가 수치로 사용<br>\n",
    "\n",
    "- classifier가 입련되면 Stratified KFold 방식으로 레이블값의 분포에 따라 학습/테스트 세트 분할<br>\n",
    "        => 회귀의 경우 : K Fold로 분할<br>\n",
    "\n",
    "** 형태<br>\n",
    "cross_val_score(estimator, X, y=None, scoring=None, cv=None, n_jobs=1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')<br>\n",
    "\n",
    "        ** estimator : 사이킷런의 Classifier, Regressor 의미\n",
    "        ** X : 피처 데이터 세트 \n",
    "        ** Y : 레이블 데이터 세트\n",
    "        ** scoring : 예측 성능 평가 지표\n",
    "        ** cv : 교차 검증 폴드 수 / 주요 파라미터 \n",
    "\n",
    "** cross_val_score() 내부<br>\n",
    "- Estimator : 교차 검증 수행<br>\n",
    "        => 학습(fit), 예측(predict), 평가(evaluation)<br>\n",
    "<br>\n",
    "\n",
    "<h5>cross_validate()란?</h5>\n",
    "\n",
    "- 여러개의 평가 지표 반환\n",
    "- 학습 데이터에 대한 성능 평가 지표와 수행 시간도 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75145ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도: [0.98 0.94 0.98]\n",
      "평균 검증별 정확도: 0.9667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "\n",
    "iris_data = load_iris()\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "data = iris_data.data\n",
    "label = iris_data.target\n",
    "\n",
    "# 성능 지표는 정확도(accuracy), 교차 검증 세트 = 3개\n",
    "scores = cross_val_score(dt_clf, data, label, scoring='accuracy', cv=3)\n",
    "print('교차 검증별 정확도:', np.round(scores, 4))\n",
    "print('평균 검증별 정확도:', np.round(np.mean(scores), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ec9407",
   "metadata": {},
   "source": [
    "<h4>3.4.4 GridSearchCV - 교차 검증과 최적 하이퍼 파라미터 튜닝</h4>\n",
    "\n",
    "- GridSearchCV : 촘촘하게 파라미터를 입력하면서 테스트하는 방식\n",
    "\n",
    "ex) 결정트리 알고리즘의 여러 하이퍼 파라미터를 순차적으로 변경하면서 최고 성능을 가지는 파라미터 조합을 찾을 때<br>\n",
    "        => 파라미터 집합 생성 후 순차적으로 적용해가며 최적화 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c0ed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_parameters = {'max_depth': [1, 2, 3], \n",
    "                   'min_samples_split':[2, 3]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efe9ab1",
   "metadata": {},
   "source": [
    "** GridSearchCV<br>\n",
    "\n",
    "- 교차 검증을 기반으로 하이퍼 파라미터의 최적 값을 찾게 해줌<br>\n",
    "- 데이터 세트 : cross-validation을 위한 학습/테스트 세트로 자동 분할<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 하이퍼 파라미터 그리드에 순차적으로 적용<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 최적의 파라미터를 찾도록 해줌<br>\n",
    "- 수행시간이 김<br><br><br>\n",
    "\n",
    "** 주요 파라미터<br>\n",
    "\n",
    "- estimator : classifier, regressor, pipeline 사용<br>\n",
    "\n",
    "- param_grid : key + 리스트값의 딕셔너리가 주어짐<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : estimator의 튜닝을 위한 파라미터명과 파라미터값 지정<br>\n",
    "\n",
    "- scoring : 예측 성능을 측정할 평가 방법을 지정<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:성능평가지표 지정 문자열 ('accuracy')로 지정하거나<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;: 별도 지정 가능<br>\n",
    "\n",
    "- cv : 교차 검증을 위해 분할되는 학습/테스트 세트의 개수 지정<br>\n",
    "\n",
    "- refit : 디폴트가 True<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;: True로 생성 시 가장 최적의 하이퍼 파라미터를 찾은 후 입력된 estimator 객체를 해당 하이퍼 파라미터로 재학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63de6b1",
   "metadata": {},
   "source": [
    "[예제]\n",
    "- train_test_split() : 학습/테스트 데이터 분리\n",
    "- GridSearchCV : 학습데이터에서 적용하여 최적 하이퍼 파라미터 추출\n",
    "- DecisionTreeClassifier 중요 하이퍼 파라미터 : max_depth, min_sample의 값을 변화시키며 최적화 진행\n",
    "- 하이퍼 파라미터 세트 : 딕셔너리 형태\n",
    "- 하이퍼 파라미터 명 : 문자열 key 값\n",
    "- 하이퍼 파라미터 값 : 리스트 형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d989ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# 데이터를 로딩하고 학습 데이터와 테스트 데이터 분리\n",
    "iris_data = load_iris()\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.2, random_state=121)\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "### 파라미터를 딕셔너리 형태로 설정\n",
    "parameters = {'max_depth':[1, 2, 3], 'min_samples_split':[2, 3]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e34ca2",
   "metadata": {},
   "source": [
    "- 학습 데이터 세트를 GridSearchCV 객체의 fit(학습 데이터 세트) 메서드에 인자로 입력\n",
    "- fit()을 사용해 학습 데이터를 cv에 기술된 폴딩 세트로 분할래 param_grid에 기술된 하이퍼 파라미터를 순차적으로 변경하면서 학습/평가 수행\n",
    "- cv_results_ : 결과 기록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2771f2fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0              0.700                0.7               0.70  \n",
       "1              0.700                0.7               0.70  \n",
       "2              0.925                1.0               0.95  \n",
       "3              0.925                1.0               0.95  \n",
       "4              0.975                1.0               0.95  \n",
       "5              0.975                1.0               0.95  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터를 로딩하고 학습 데이터와 테스트 데이터 분리\n",
    "iris_data = load_iris()\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.2, random_state=121)\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "### 파라미터를 딕셔너리 형태로 설정\n",
    "parameters = {'max_depth':[1, 2, 3], 'min_samples_split':[2, 3]}\n",
    "\n",
    "#  param_grid의 하이퍼 파라미터를 3개의 train, test set fold로 나누어 테스트 수행 설정\n",
    "### refit=True가 Default, True면 가장 좋은 파라미터 설정으로 재학습\n",
    "grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True)\n",
    "\n",
    "# 붓꽃 학습 데이터로 param_grid의 하이퍼 파라미터를 순차적으로 학습/평가\n",
    "grid_dtree.fit(x_train, y_train)\n",
    "\n",
    "# GrodSearchCV 결과를 추출해 DataFrame으로 변환\n",
    "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df[ ['params', 'mean_test_score', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score'] ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a53a3e",
   "metadata": {},
   "source": [
    "[예제 결과]\n",
    "- max_depth, min_samples_split 순차적으로 6번 변경하면서 학습/평가 수행\n",
    "\n",
    "- 'params': 수행할 때 마다 적용된 하이퍼 파라미터 값\n",
    "\n",
    "- Index(4)번의 경우 :  'rank_test_score'=1 \n",
    "\n",
    "        => {'max_depth': 3, 'min_samples_split': 2}\n",
    "\n",
    "        => 해당 값으로 평가한 결과 : 예측 성능이 1위임을 의미\n",
    "\n",
    "- Index(5)번의 경우 : 공동 1위임\n",
    "\n",
    "- split0_test_score : split0~2는 CV가 3인 경우를 의미\n",
    "\n",
    "        => 폴딩 세트에서 각각 테스트한 성능 수치\n",
    "\n",
    "- mean_test_score : 세 개의 성능 수치를 평균한 값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598648aa",
   "metadata": {},
   "source": [
    "** 주요 칼럼별 의미<br>\n",
    "- params 칼렘에는 수행할 때마다 적용된 개별 하이퍼 파라미터값을 나타냄<br>\n",
    "- rank_test_score : 하이퍼 파라미터별로 성능이 좋은 score 순위를 나타냄, 1이 가장 뛰어난 순위 = 최적의 하이퍼 파라미터임<br>\n",
    "- mean_test_score : 개별 하이퍼 파라미터별로 CV의 폴딩 테스트 세트에 대해 총 수행한 평가 평균값<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cc0d92",
   "metadata": {},
   "source": [
    "** GridSearchCV의 fit()\n",
    "- 최고 성능을 나타낸 하이퍼 파라미터의 값, 당시의 평가 경과 값이 저장\n",
    "- best_params_\n",
    "- best_score_\n",
    "\n",
    "=> cv_results_의 rank_test_score가 1일 때의 값임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dddb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터: {'max_depth': 3, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 정확도:0.9750\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터를 로딩하고 학습 데이터와 테스트 데이터 분리\n",
    "iris_data = load_iris()\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.2, random_state=121)\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "### 파라미터를 딕셔너리 형태로 설정\n",
    "parameters = {'max_depth':[1, 2, 3], 'min_samples_split':[2, 3]}\n",
    "\n",
    "#  param_grid의 하이퍼 파라미터를 3개의 train, test set fold로 나누어 테스트 수행 설정\n",
    "### refit=True가 Default, True면 가장 좋은 파라미터 설정으로 재학습\n",
    "grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True)\n",
    "\n",
    "# 붓꽃 학습 데이터로 param_grid의 하이퍼 파라미터를 순차적으로 학습/평가\n",
    "grid_dtree.fit(x_train, y_train)\n",
    "\n",
    "# GrodSearchCV 결과를 추출해 DataFrame으로 변환\n",
    "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df[ ['params', 'mean_test_score', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score'] ]\n",
    "\n",
    "print('GridSearchCV 최적 파라미터:', grid_dtree.best_params_)\n",
    "# {0:.f} == 소수점 4자리 수 반올림한 값\n",
    "print('GridSearchCV 최고 정확도:{0:.4f}'.format(grid_dtree.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81061bc",
   "metadata": {},
   "source": [
    "[예제]\n",
    "학습된 best_estimator_를 이용해 앞에서 train_test_split() 으로 분리한 테스트 데 이터 세트에 대해 예측하고 성능을 평가\n",
    "\n",
    "[결론]\n",
    "학습 데이터를 GridSearchCV()를 이용해 최적 하이퍼 파라미터 튜닝을 수행한 뒤에 별도의 테스트 세트에서 이를 평가하는 것이 일반적인 머신러닝 모델 적용 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15e7b3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 세트 정확도: 0.9667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터를 로딩하고 학습 데이터와 테스트 데이터 분리\n",
    "iris_data = load_iris()\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.2, random_state=121)\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "### 파라미터를 딕셔너리 형태로 설정\n",
    "parameters = {'max_depth':[1, 2, 3], 'min_samples_split':[2, 3]}\n",
    "\n",
    "#  param_grid의 하이퍼 파라미터를 3개의 train, test set fold로 나누어 테스트 수행 설정\n",
    "### refit=True가 Default, True면 가장 좋은 파라미터 설정으로 재학습\n",
    "grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True)\n",
    "\n",
    "# 붓꽃 학습 데이터로 param_grid의 하이퍼 파라미터를 순차적으로 학습/평가\n",
    "grid_dtree.fit(x_train, y_train)\n",
    "\n",
    "# GrodSearchCV 결과를 추출해 DataFrame으로 변환\n",
    "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df[ ['params', 'mean_test_score', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score'] ]\n",
    "\n",
    "# print('GridSearchCV 최적 파라미터:', grid_dtree.best_params_)\n",
    "# {0:.f} == 소수점 4자리 수 반올림한 값\n",
    "# print('GridSearchCV 최고 정확도:{0:.4f}'.format(grid_dtree.best_score_))\n",
    "\n",
    "# GridSearchCV의 refit으로 이미 학습된 estimator 반환\n",
    "estimator = grid_dtree.best_estimator_\n",
    "\n",
    "# GridSearchCV의 best_estimator_는 이미 최적 학습이 됐으므로 별도 학습이 필요 없음\n",
    "pred = estimator.predict(x_test)\n",
    "print('테스트 데이터 세트 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7e677a",
   "metadata": {},
   "source": [
    "<h3>3.5 데이터 전처리(Data Preprocessing)</h3>\n",
    "\n",
    "- 결손값 : NaN, Null 값 허용되지 않음<br>\n",
    "        => Null값의 경우 고정된 다른 값으로 변환돼야 함<br>\n",
    "\n",
    "** Null 값 처리<br>\n",
    "- Null 값 적을 때 : 피처의 평균값으로 대체 가능<br>\n",
    "- Null 값 많을 때 : 피처 드롭<br>\n",
    "- Null 값 일정 : 정밀한 대체 값 선정<br>\n",
    "\n",
    "- 문자열 값 : 입력값으로 허용 안됨, 인코딩을 통해 숫자형으로 변환 필요<br>\n",
    "- 문자열 피처 : 카테고리형 피처, 텍스트형 피처<br>\n",
    "            => 카테고리형 피처 : 코드값으로 표현<br>\n",
    "            => 텍스트형 피처 : 피처 벡터화 또는 불필요한 피처는 삭제<br>\n",
    "            => 단순 문자열의 경우 인코딩 x, 삭제하는게 좋음<br>\n",
    "                (예측 성능을 떨어트리므로)\n",
    "\n",
    "<h4>3.5.1 데이터 인코딩</h4>\n",
    "- 주요 인코딩 방식 : 레이블 인코딩, 원-핫 인코딩<br>\n",
    "\n",
    "(1) 레이블 인코딩(Lable encoding)<br>\n",
    "- 카테고리 피처를 코드형 숫자 값으로 변환하는 것<br>\n",
    "    ex) 냉장고, 세탁기, 컴퓨터  => 카테고리 피처<br>\n",
    "        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3&nbsp;&nbsp;&nbsp;=> 숫자형<br>\n",
    "        ** 단, '01'과 같은 코드값은 안됨<br>\n",
    "\n",
    "- 레이블 인코딩구현 : LabelEncoder클래스 사용<br>\n",
    "                => LabelEncoder객체 생성 후 fit()과 transform()을 호출해 진행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5291f653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 반환값: [0 1 4 5 3 3 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
    "\n",
    "# LabelEncoder를 객체로 생성한 후, fit()과 transform()으로 레이블 인코딩 수행\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "print('인코딩 반환값:', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ad034d",
   "metadata": {},
   "source": [
    "** LabelEncoder객체의 classes_속성값<br>\n",
    "classes_ : 문자열 값이 어떤 숫자값으로 인코딩됐는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ca252de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 클래스: ['TV' '냉장고' '믹서' '선풍기' '전자레인지' '컴퓨터']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
    "\n",
    "# LabelEncoder를 객체로 생성한 후, fit()과 transform()으로 레이블 인코딩 수행\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "# print('인코딩 반환값:', labels)\n",
    "print('인코딩 클래스:', encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e983564f",
   "metadata": {},
   "source": [
    "** 인코딩된 값을 다시 디코딩<br>\n",
    "inverse_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea406210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "디코딩 원본값: ['전자레인지' '컴퓨터' '믹서' 'TV' '냉장고' '냉장고' '선풍기' '선풍기']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
    "\n",
    "# LabelEncoder를 객체로 생성한 후, fit()과 transform()으로 레이블 인코딩 수행\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "# print('인코딩 반환값:', labels)\n",
    "# print('인코딩 클래스:', encoder.classes_)\n",
    "print('디코딩 원본값:', encoder.inverse_transform([4, 5, 2, 0, 1, 1, 3, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6939fac",
   "metadata": {},
   "source": [
    "** 래이블 인코딩의 특징\n",
    "- 숫자값은 크고 작음에 대한 특성이 존재하므로, 문자열값이 숫자형 카테고리로 변환되며 예측성능이 떨어지는 경우 발생\n",
    "- 선형회귀와 같은 ML알고리즘에서 적용되면 안됨\n",
    "- 위와 같은 경우 One-Hot Encoding 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e22f0ad",
   "metadata": {},
   "source": [
    "<h4>3.5.2 원-핫 인코딩(One-Hot Encoding)</h4>\n",
    "- 피처값의 유형에 따라 새로운 피처를 추가해 고유 값에 해당하는 칼럼에만 1을 표시, 나머지는 0 으로 인코딩<br>\n",
    "\n",
    "** 형태<br>\n",
    "ex) 행 피처 고유값 => 열 형태 차원 변환<br>\n",
    "    고유값 칼럼 = 1, 나머지 칼럼 = 0 지정 <br>\n",
    "\n",
    "\n",
    "** OneHotEncoder\n",
    "- LabelEncoder와 다르게 입력값으로 2차원 데이터 필요\n",
    "- OneHotEncoder을 이용해 변환된 값이 희소행렬(Spare Matrix)형태이므로 다시 toarray()메서드를 이용해 밀집행렬(Dense Matrix)로 변환해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "177918b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원-핫 인코딩 데이터\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n",
      "원-핫 인코딩 데이터 차원\n",
      "(8, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
    "\n",
    "# 2차원 ndarray로 변환\n",
    "items = np.array(items).reshape(-1, 1)\n",
    "\n",
    "# 원-핫 인코딩 적용\n",
    "oh_encoder = OneHotEncoder()\n",
    "oh_encoder.fit(items)\n",
    "oh_labels = oh_encoder.transform(items)\n",
    "\n",
    "# OneHotEncoder로 변환한 결과는 희소행렬이므로 toarray()사용해 밀집 행렬로 변환\n",
    "print('원-핫 인코딩 데이터')\n",
    "print(oh_labels.toarray())\n",
    "print('원-핫 인코딩 데이터 차원')\n",
    "print(oh_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc07e5f",
   "metadata": {},
   "source": [
    "** get_dummies()<br>\n",
    "- 판다스의 원-핫 인코딩 지원 API<br>\n",
    "- 숫자형 값으로 변환하지 않고도 바로 변환가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e2a99cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_TV</th>\n",
       "      <th>item_냉장고</th>\n",
       "      <th>item_믹서</th>\n",
       "      <th>item_선풍기</th>\n",
       "      <th>item_전자레인지</th>\n",
       "      <th>item_컴퓨터</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_TV  item_냉장고  item_믹서  item_선풍기  item_전자레인지  item_컴퓨터\n",
       "0     True     False    False     False       False     False\n",
       "1    False      True    False     False       False     False\n",
       "2    False     False    False     False        True     False\n",
       "3    False     False    False     False       False      True\n",
       "4    False     False    False      True       False     False\n",
       "5    False     False    False      True       False     False\n",
       "6    False     False     True     False       False     False\n",
       "7    False     False     True     False       False     False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'item':['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']})\n",
    "\n",
    "pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f080dc5",
   "metadata": {},
   "source": [
    "<h3>3.5.2 피처 스케일링 정규화</h3>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
