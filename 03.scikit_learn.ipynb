{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d7e48d6",
   "metadata": {},
   "source": [
    "<h1>scikit-learn</h1>\n",
    "- 프레임워크, API제공"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e04f8a",
   "metadata": {},
   "source": [
    "<h3>3.1 분류 (Classification)</h3>\n",
    "- 지도학습(Aupervised learning) 방법 중 하나\n",
    "\n",
    "<h5>** 지도학습</h5>\n",
    "\n",
    "- 다양한 피처와 분류 결정값인 레이블(Lable) 데이터로 모델을 한습한 후, 별도의 테스트 데이터 세트에서 미지의 레이블을 예측<br>\n",
    "\n",
    "- 먕확한 정답이 주어진 데이터 先학습， 後 미지의 정답 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ba7769",
   "metadata": {},
   "source": [
    "<h5>사이킷런 모듈</h5>\n",
    "\n",
    "(1) sklearn.datasets\n",
    "- 사이킷런 자체 제공 데이터 세트 생성 모듈\n",
    "\n",
    "(2) sklearn.tree\n",
    "- 트리기반 ML 알고리즘\n",
    "\n",
    "(3) sklearn.model_selection\n",
    "- 학습 데이터, 검증 데이터 통칭\n",
    "- 하이퍼 파라미터를 통해 머신러닝 알고리즘의 성능 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69cef40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris target값: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "iris target명: ['setosa' 'versicolor' 'virginica']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 붓꽃 데이터 세트 로딩\n",
    "iris = load_iris()\n",
    "\n",
    "# iris_data : 붓꽃 데이터 세트에서 feature만으로 된 데이터를 numpy로 가지고 있음\n",
    "iris_data = iris.data\n",
    "\n",
    "# iris_label : 붓꽃 데이터 세트에서 label(결정 값) 데이터를 numpy로 가지고 있음\n",
    "iris_label = iris.target\n",
    "print('iris target값:', iris_label)\n",
    "print('iris target명:', iris.target_names)\n",
    "\n",
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "iris_df['label'] = iris_label\n",
    "iris_df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b66e383",
   "metadata": {},
   "source": [
    "<h5>▲ Result </h5>\n",
    "\n",
    "(1) feature\n",
    "- sepal length\n",
    "- sepal width\n",
    "- petal length\n",
    "- petal width\n",
    "\n",
    "(2) label\n",
    "- 0 : Setosa 품종\n",
    "- 1 : versicolor 품종\n",
    "- 2 : verginica 품종"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aef85df",
   "metadata": {},
   "source": [
    "<h4>학습용 데이터 및 테스트용 데이터 분리</h4>\n",
    "\n",
    "- 학습 데이터로 학습된 모델의 성능 평가를 위해 테스트 데이터 세트 필요\n",
    "- train_test_split()\n",
    "\n",
    "(1) train_test_split()\n",
    "- 학습 데이터와 테스트 데이터를 test_size 파라미터 입력값의 비율로 분할\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74926a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris target값: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "iris target명: ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 붓꽃 데이터 세트 로딩\n",
    "iris = load_iris()\n",
    "\n",
    "# iris_data : 붓꽃 데이터 세트에서 feature만으로 된 데이터를 numpy로 가지고 있음\n",
    "iris_data = iris.data\n",
    "\n",
    "# iris_label : 붓꽃 데이터 세트에서 label(결정 값) 데이터를 numpy로 가지고 있음\n",
    "iris_label = iris.target\n",
    "print('iris target값:', iris_label)\n",
    "print('iris target명:', iris.target_names)\n",
    "\n",
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "iris_df['label'] = iris_label\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris_data, iris_label, test_size = 0.2, random_state=11)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00b489d",
   "metadata": {},
   "source": [
    "feature\n",
    "- iris_data\n",
    "\n",
    "lable\n",
    "- iris_lable\n",
    "\n",
    "test data set 비율\n",
    "- test_size = 0.2\n",
    "\n",
    "난수 발생 값 (호출 마다 같은 학습/테스트 용 데이터 세트 생성을 위한)<br>\n",
    "- random_state\n",
    "\n",
    "** train_test_split() 호출 시 무작위로 데이터를 분리하므로 random_state() 지정 필요<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4adabdd",
   "metadata": {},
   "source": [
    "** DecisionTreeClassifier()\n",
    "- 의사결정 트리 클래스\n",
    "- random_state= 지정 \n",
    "- 학습/예측 결과 출력\n",
    "- fit() : 학습용 피처 데이터 속성과 결정 값 데이터 세트 입력 \n",
    "\n",
    "\n",
    "** fit()\n",
    "- 모델을 학습하는 단계 (피처와 레이블로)\n",
    "\n",
    "** predict()\n",
    "- 학습이 끝난 모델이 답을 내는 단계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e499d7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris target값: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "iris target명: ['setosa' 'versicolor' 'virginica']\n",
      "예측 정확도:  0.933333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 붓꽃 데이터 세트 로딩\n",
    "iris = load_iris()\n",
    "\n",
    "# iris_data : 붓꽃 데이터 세트에서 feature만으로 된 데이터를 numpy로 가지고 있음\n",
    "iris_data = iris.data\n",
    "\n",
    "# iris_label : 붓꽃 데이터 세트에서 label(결정 값) 데이터를 numpy로 가지고 있음\n",
    "iris_label = iris.target\n",
    "print('iris target값:', iris_label)\n",
    "print('iris target명:', iris.target_names)\n",
    "\n",
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "iris_df['label'] = iris_label\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris_data, iris_label, test_size = 0.2, random_state=11)\n",
    "\n",
    "# DecisionTreeClassifier 객체 생성\n",
    "dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "\n",
    "# 학습 수행\n",
    "dt_clf.fit(x_train, y_train)\n",
    "\n",
    "# 학습 완료된 DecisionTreeClassifier 객체에서 테스트 데이터 세트로 예측 수행\n",
    "pred = dt_clf.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('예측 정확도: {0: 4F}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3983ffa3",
   "metadata": {},
   "source": [
    "** 정확도 측정\n",
    "\n",
    "- accuracy_acore()\n",
    "- 실제 데이터 세트, 예측 레이블 데이터 세트 순으로 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67a5bf9",
   "metadata": {},
   "source": [
    "** 분류 예측 프로세스\n",
    "\n",
    "(1) 데이터 세트 분리 : 학습/테스트 데이터 분리<br>\n",
    "(2) 모델 학습 : 학습 데이터 기반으로 모델 학습<br>\n",
    "(3) 예측 수행 : 학습된 ML 모델로 테스트 데이터의 분류 예측<br>\n",
    "(4) 평가 : 예측된 결과값, 테스트 데이터의 실제 결과값 비교 후 모델 성능 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f4adbf",
   "metadata": {},
   "source": [
    "<h3>3.2 사이킷런 기반 프레임워크</h3>\n",
    "\n",
    "<h4>3.2.1 Estimator 이해 및 fit(), predict()</h4>\n",
    "\n",
    "- fit() : ML 모델 학습\n",
    "- predict() : 학습된 모델의 예측\n",
    "- 지도학습 : 분류(Classifier) / 회귀(Regressor) 클래스에서 fit(), predict()으로 간단하게 학습 및 예측 결과 반환 가능\n",
    "- Estimator 클래스 = 분류(Classifier) + 회귀(Regressor)\n",
    "\n",
    "\n",
    "- cross_val_score() : evaluation 함수\n",
    "- GridSearchCV : 파라미터 튜닝\n",
    "- cross_val_score(), GridSearchCV.fit() : Estimator의 fit(), predict()를 호출해 평가 및 파라미터 튜닝 수행\n",
    "\n",
    "\n",
    "<h5>** 비지도 학습에서의 fit(), transform() 사용법</h5>\n",
    "\n",
    "- 비지도학습 : 차원 축소 / 클러스터링 / 피처 추출(Feature Extraction) \n",
    "- fit() : 비지도 학습 및 피처 추출에서 fit() 사용시 압력데이터의 형태에 맞춰 데이터를 변환해주기 위해 사전 구조를 맞추는 작업 진행\n",
    "- transform() : 차원 변환, 클러스터링, 피처 추출 등 실제 작업 진행\n",
    "\n",
    "- fit_transform() : fit()과 transform()의 결합물<br>\n",
    "    => fit()과 transform()을 별도로 호출하지 않아도 됨\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b32794b",
   "metadata": {},
   "source": [
    "<h4>3.2.2 사이킷런의 주요 모듈</h4>\n",
    "\n",
    "\n",
    "<h5>(1) 예제 데이터</h5>\n",
    "\n",
    "- sklearn.datasets : 내장돤 예제 제공  데이터 세트\n",
    "\n",
    "<h5>(2) 피처 처리</h5>\n",
    "\n",
    "- sklearn.preprocessing<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 데이터 전처리에 필요한 가공 기능 (문자열을 숫자형 코드값으로 인코딩, 정규화, 스케일링 등)\n",
    "\n",
    "- sklearn.feature_selection<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 일고리즘에 큰 영향을 미치는 피처를 우선순위대로 셀렉션 작업을 수행 기능 제공\n",
    "\n",
    "- sklearn.feature_extraction<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 텍스트, 이미지 데이터의 벡터화된 피처를 추출시 사용<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 텍스트 데이터 내 Count Vectorizer, TF-IDF Vectorizer 생산 기능 제공<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 텍스트 데이터 피처 추출 : sklearn.feature_extraction.text<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 이미지 데이터 피처 추출 : sklearn.feature_extraction.image<br>\n",
    "\n",
    "<h5>(3) 피처 처리 & 차원 축소</h5>\n",
    "\n",
    "- sklearn.decomposition<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 차원 축소 관련 알고리즘 지원 모듈 <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> PCA, NMF, Truncated SVD 등을 이용해 차원 축소<br>\n",
    "\n",
    "<h5>(4) 데이터 분리, 검증 & 파라미터 튜닝</h5>\n",
    "\n",
    "- sklearn.model_selection<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 교차 검증을 위한 학습/테스트 용 분리, 그리드 서치로 최적의 파라미터 추출 등 API 제공<br>\n",
    "\n",
    "<h5>(5) 평가</h5>\n",
    "\n",
    "- sklearn.metric<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 분류, 회귀, 클러스터링, 페어와이즈(Pairwise)에 대한 다양한 성능 측정 방법<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> Accuracy, Precsion, Recal, ROC-AUC, RMSE 제공<br>\n",
    "\n",
    "<h5>(6) ML 알고리즘</h5>\n",
    "\n",
    "- sklearn.ensemble<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 앙상블 알고리즘 제공<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 랜덤 포레스트, 에이다 부스트, 그래디언트 부스팅 제공<br>\n",
    "\n",
    "- sklearn.linear_model<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 선형회귀, 릿지(Ridge), 라쏘(Lasso), 로지스틱 회귀 등 회귀 관련 알고리즘 지원<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> SGD(Stochastic Gradient Descent) 알고리즘 제공<br>\n",
    "\n",
    "- sklearn.naive_bayes<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 나이브 베이즈 알고리즘 제공<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 기우시안 NB, 다항분포 NB 제공<br>\n",
    "\n",
    "- sklearn.neighbors<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 최근접 이웃 알고리즘, K-NN<br>\n",
    "\n",
    "- sklearn.svm<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 서포트 벡터 머신 제공<br>\n",
    "\n",
    "- sklearn.tree<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 의사결정 트리 제공<br>\n",
    "\n",
    "- sklearn.cluster<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 비지도 클러스터링 제공<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> K-평균, 계층형, DBSCAN<br>\n",
    "\n",
    "<h5>(7) 유틸리티</h5>\n",
    "\n",
    "- sklearn.pipeline<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=> 피처 처리 등 변환, ML 알고리즘 학습, 예측 등을 함께 묶어 실행 가능한 유틸리티 제공<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3070489d",
   "metadata": {},
   "source": [
    "<h4>3.2.3 내장돤 예제 데이터 세트</h4>\n",
    "- fetch : 데이터 크기가 커 인터넷에서 다운 받아 사용\n",
    "\n",
    "<h5>** 표본 데이터 생성기</h5>\n",
    "\n",
    "(1) 분류<br>\n",
    "- datasets.make_classifications()<br>\n",
    "    => 분류를 위한 데이터 세트 생성<br>\n",
    "    => 높은 상관도, 불필요한 속성 등 노이즈 효과를 위한 데이터 무작위로 생성<br>\n",
    "\n",
    "(2) 클러스터링<br>\n",
    "- datasets.make_classifications()<br>\n",
    "    => 클러스터링를 위한 데이터 세트 무작위 생성<br>\n",
    "    => 군집 지정 개수에 따라 여러 가지 클러스터링을 위한 데이터 무작위로 생성<br>\n",
    "\n",
    "<h5>** 내장 데이터 구성</h5>\n",
    "- 딕셔너리 형태<br>\n",
    "- 키 : data, target, target_name, feature_names, DESCR로 구성<br>\n",
    "\n",
    "(1) 넘파이 배열(ndarray)<br>\n",
    "&nbsp;&nbsp;&nbsp;=> data : 피처의 데이터 세트 <br>\n",
    "&nbsp;&nbsp;&nbsp;=> target : 분류 시 레이블 값 / 회귀 시 숫자 결과값 데이터 세트<br>\n",
    "\n",
    "(2) 넘파이 배열(ndarray) & 파이썬 list<br>\n",
    "&nbsp;&nbsp;&nbsp;=> target_name : 개별 레이블 이름<br>\n",
    "&nbsp;&nbsp;&nbsp;=> feature_names : 피처 명<br>\n",
    "\n",
    "(3) String 타입<br>\n",
    "&nbsp;&nbsp;&nbsp;=> DESCR : 데이터 세트 설명 및 각 피처의 설명<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa19da72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils._bunch.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "print(type(iris_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a912c67f",
   "metadata": {},
   "source": [
    "** bunch\n",
    "- 파이썬 딕셔너리 형태와 유사 / 딕셔너리 형태의 값 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef0af454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트의 키들: dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "keys = iris_data.keys()\n",
    "\n",
    "print('붓꽃 데이터 세트의 키들:', keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f4d2056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " feature_names의 type: <class 'list'>\n",
      "\n",
      " feature_names의 shape: 4\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "\n",
      " target_names의 type: <class 'numpy.ndarray'>\n",
      "\n",
      " target_names의 shape: 3\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "\n",
      " data의 type: <class 'numpy.ndarray'>\n",
      "data 의 shape: (150, 4)\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "\n",
      " data의 type: <class 'numpy.ndarray'>\n",
      "data 의 shape: (150,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "keys = iris_data.keys()\n",
    "\n",
    "print('\\n feature_names의 type:', type(iris_data.feature_names))\n",
    "print('\\n feature_names의 shape:', len(iris_data.feature_names))\n",
    "print(iris_data.feature_names)\n",
    "\n",
    "print('\\n target_names의 type:', type(iris_data.target_names))\n",
    "print('\\n target_names의 shape:', len(iris_data.target_names))\n",
    "print(iris_data.target_names)\n",
    "\n",
    "print('\\n data의 type:', type(iris_data.data))\n",
    "print('data 의 shape:', iris_data.data.shape)\n",
    "print(iris_data['data'])\n",
    "\n",
    "print('\\n data의 type:', type(iris_data.target))\n",
    "print('data 의 shape:', iris_data.target.shape)\n",
    "print(iris_data.target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a39fc90",
   "metadata": {},
   "source": [
    "<h3>3.3 Model Selection 모듈 소개</h3>\n",
    "\n",
    "- 학습 / 테스트 데이터 분리\n",
    "- 교차 검증 분할 및 평가\n",
    "- Estimator의 하이퍼 파라미터 튜닝\n",
    "\n",
    "<h4>3.3.1 학습/테스트 데이터 분리 - train_test_split()</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "532c4f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 학습과 예측을 동일 데이터 세트로 진행 예제\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "df_clf = DecisionTreeClassifier()\n",
    "train_data = iris.data\n",
    "train_label = iris.target\n",
    "df_clf.fit(train_data, train_label)\n",
    "\n",
    "# 학습 데이터 세트로 예측 수행\n",
    "pred = df_clf.predict(train_data)\n",
    "print('예측 정확도:', accuracy_score(train_label, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
